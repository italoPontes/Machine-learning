{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade de Regressão Linear\n",
    "\n",
    "## Código-fonte disponível em: [link](https://github.com/italoPontes/Machine-learning/tree/master/Tarefas/Regress%C3%A3o-Linear-Simples-do-Zero)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#Federal University of Campina Grande (UFCG)\n",
    "#Author: Ítalo de Pontes Oliveira\n",
    "#Adapted from: Siraj Raval\n",
    "#Available at: https://github.com/llSourcell/linear_regression_live\n",
    "\n",
    "#The optimal values of m and b can be actually calculated with way less effort than doing a linear regression. \n",
    "#this is just to demonstrate gradient descent\n",
    "\n",
    "\"\"\"This project will calculate linear regression\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy\n",
    "from numpy import *\n",
    "import sys\n",
    "\n",
    "# y = mx + b\n",
    "# m is slope, b is y-intercept\n",
    "## Compute the errors for a given line\n",
    "#  @param b Is the linear coefficient\n",
    "#  @param m Is the angular coefficient\n",
    "#  @param x Domain points\n",
    "#  @param y Domain points\n",
    "def compute_error_for_line_given_points(w0, w1, x, y):\n",
    "\ttotalError = sum((y - (w1 * x + w0)) ** 2)\n",
    "\ttotalError /= float(len(x))\n",
    "\treturn totalError\n",
    "\n",
    "## Calculate a new linear and angular coefficient step by a learning rate. \n",
    "#  @param w0_current Current linear coefficient\n",
    "#  @param w1_current Current linear coefficient\n",
    "#  @param x Domain points\n",
    "#  @param y Image points\n",
    "#  @param learningRate The rate in which the gradient will be changed in one step\n",
    "def step_gradient(w0_current, w1_current, x, y, learningRate):\n",
    "\tw0_gradient = 0\n",
    "\tw1_gradient = 0\n",
    "\tnorma = 0\n",
    "\tN = float(len(x))\n",
    "\t\n",
    "\tw0_gradient = -2 * sum( y - ( w0_current + ( w1_current * x ) ) ) / N\n",
    "\tw1_gradient = -2 * sum( ( y - ( w0_current + ( w1_current * x ) ) ) * x ) / N\n",
    "\n",
    "\tnorma = numpy.linalg.norm(w0_gradient - w1_gradient)\n",
    "\t\n",
    "\tnew_w0 = w0_current - (learningRate * w0_gradient)\n",
    "\tnew_w1 = w1_current - (learningRate * w1_gradient)\n",
    "\t\n",
    "\treturn [new_w0, new_w1, norma]\n",
    "\n",
    "## Run the descending gradient\n",
    "#  @param x Domain points\n",
    "#  @param y Image points\n",
    "#  @param starting_w0 Linear coefficient initial\n",
    "#  @param starting_w1 Angular coefficient initial\n",
    "#  @param learning_rate The rate in which the gradient will be changed in one step\n",
    "#  @param num_iterations Interactions number that the slope line will approximate before a stop.\n",
    "def gradient_descent_runner(x, y, starting_w0, starting_w1, learning_rate, num_iterations):\n",
    "\tw0 = starting_w0\n",
    "\tw1 = starting_w1\n",
    "\trss_by_step = 0\n",
    "\trss_total = []\n",
    "\tnorma = learning_rate\n",
    "\titeration_number = 0\n",
    "\t\n",
    "\tcondiction = True\n",
    "\tif num_iteractions < 1:\n",
    "\t\tcondiction = False\n",
    "    \n",
    "\twhile (norma > 0.001 and not condiction) or ( iteration_number < num_iteractions and condiction):\n",
    "\t\tw0, w1, norma = step_gradient(w0, w1, x, y, learning_rate)\n",
    "\t\t\n",
    "\t\trss_by_step = compute_error_for_line_given_points(w0, w1, x, y)\n",
    "\t\trss_total.append(rss_by_step)\n",
    "\t\titeration_number += 1\n",
    "\tshow_figure(rss_total, \"Iteraction\", \"RSS\")\n",
    "\t\n",
    "\treturn [w0, w1, iteration_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Questões\n",
    "\n",
    "\n",
    "#### 1. Rode o mesmo programa nos dados contendo anos de escolaridade (primeira coluna) versus salário (segunda coluna). Baixe os dados aqui. Esse exemplo foi trabalhado em sala de aula em várias ocasiões. Os itens a seguir devem ser respondidos usando esses dados.\n",
    "\n",
    "RESOLUÇÃO: Arquivo baixado, encontra-se no diretório atual com o nome \"income.csv\".\n",
    "\n",
    "#### 2. Modifique o código original para imprimir o RSS a cada iteração do gradiente descendente.\n",
    "\n",
    "RESOLUÇÃO: Foi preferível adicionar uma nova funcionalidade ao código. Ao final da execução é salvo um gráfico com o RSS para todas as iterações.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Show figure \n",
    "#  @param data Data to show in the graphic.\n",
    "#  @param xlabel Text to be shown in abscissa axis.\n",
    "#  @param ylabel Text to be shown in ordinate axis.\n",
    "def show_figure(data, xlabel, ylabel):\n",
    "\tplt.cla() # clears an axis\n",
    "\tplt.clf() # clears the entire current figure \n",
    "\tplt.close() # closes a window\n",
    "\tplt.plot(data)\n",
    "\tplt.xlabel(xlabel)\n",
    "\tplt.ylabel(ylabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. O que acontece com o RSS ao longo das iterações (aumenta ou diminui) se você usar 1000 iterações e um learning_rate (tamanho do passo do gradiente) de 0.001? Por que você acha que isso acontece?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'num_iteractions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-703bccef0abd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0miterations_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgradient_descent_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarting_w0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarting_w1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-f732014f5745>\u001b[0m in \u001b[0;36mgradient_descent_runner\u001b[0;34m(x, y, starting_w0, starting_w1, learning_rate, num_iterations)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mcondiction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnum_iteractions\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m                 \u001b[0mcondiction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'num_iteractions' is not defined"
     ]
    }
   ],
   "source": [
    "points = genfromtxt(\"income.csv\", delimiter=\",\")\n",
    "x = points[:,0] \n",
    "y = points[:,1]\n",
    "\n",
    "starting_w0 = 0\n",
    "starting_w1 = 0\n",
    "\n",
    "learning_rate = 0.001\n",
    "iterations_number = 100\n",
    "gradient_descent_runner(x, y, starting_w0, starting_w1, learning_rate, iterations_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "iterations_number = 1000\n",
    "gradient_descent_runner(x, y, starting_w0, starting_w1, learning_rate, iterations_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
